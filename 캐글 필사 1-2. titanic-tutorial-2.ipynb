{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 3. Feature Engineering\n\n본격적으로 Feature Engineering을 시작하고자 한다.\n먼저 numpy, pandas, matplotlib, seaborn과 같은 라이브러리를 가져오는 기본 세팅을 시작한다. 그 다음 해당 자료를 불러온다. 타이타닉 튜토리얼 1에서 했던 방법 그대로 하면 되니 복습하듯이 따라쳐보자.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pandas import Series\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn')\nsns.set(font_scale=2.5) \nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n\ndf_train = pd.read_csv('../input/titanic/train.csv')\ndf_test = pd.read_csv('../input/titanic/test.csv')\ndf_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 # 자신을 포함해야하니 1을 더합니다\ndf_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1 # 자신을 포함해야하니 1을 더합니다\n\ndf_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean()\n\ndf_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\ndf_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i > 0 else 0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-21T12:57:24.448774Z","iopub.execute_input":"2022-07-21T12:57:24.449234Z","iopub.status.idle":"2022-07-21T12:57:25.692033Z","shell.execute_reply.started":"2022-07-21T12:57:24.449142Z","shell.execute_reply":"2022-07-21T12:57:25.690605Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### 3.1 Fill Null\n\n#### 3.1.1 Fill Null in Age using title\n\nAge column에는 null data가 177개나 있었다. 이를 채울 수 있는 여러 아이디어가 있겠지만, 여기서 우리는 title + statistics를 사용할 것이다.\n\n영어에서는 Miss, Mr, Mrs 같은 title이 존재한다. 각 탑승객의 이름에는 꼭 이런 title이 들어가게 되는데, 이를 사용해 보자.\n\npandas series에는 data를 string으로 바꿔주는 str method와 정규표현식을 적용시켜 주는 extract method가 있다. 이를 사용하여 title을 쉽게 추출할 수 있다. title을 initial column에 저장하도록 하겠다.","metadata":{}},{"cell_type":"code","source":" df_train['Name']\n\n# 이름을 불러와 보니 이름마다 Mr, Mrs, Miss와 같은 title이 존재함을 알 수 있다.\n# 이를 토대로 대략적인 나이를 예측하여 이를 수치로 나타낼 것이다.","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:25.694747Z","iopub.execute_input":"2022-07-21T12:57:25.695539Z","iopub.status.idle":"2022-07-21T12:57:25.710821Z","shell.execute_reply.started":"2022-07-21T12:57:25.695489Z","shell.execute_reply":"2022-07-21T12:57:25.709816Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_train['Name'].str.extract('([A-Za-z]+)\\.')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:25.712651Z","iopub.execute_input":"2022-07-21T12:57:25.713403Z","iopub.status.idle":"2022-07-21T12:57:25.751212Z","shell.execute_reply.started":"2022-07-21T12:57:25.713324Z","shell.execute_reply":"2022-07-21T12:57:25.750322Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train['Initial'] = df_train.Name.str.extract('([A-Za-z]+)\\.')\ndf_test['Initial'] = df_test.Name.str.extract('([A-Za-z]+)\\.')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:25.754072Z","iopub.execute_input":"2022-07-21T12:57:25.754828Z","iopub.status.idle":"2022-07-21T12:57:25.769180Z","shell.execute_reply.started":"2022-07-21T12:57:25.754779Z","shell.execute_reply":"2022-07-21T12:57:25.767927Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"pandas의 crosstab을 이용해 우리가 추출한 initial과 sex 간의 count를 살펴보자.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df_train['Initial'], df_train['Sex']).T.style.background_gradient(cmap=\"summer_r\")","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:25.771159Z","iopub.execute_input":"2022-07-21T12:57:25.771623Z","iopub.status.idle":"2022-07-21T12:57:25.903156Z","shell.execute_reply.started":"2022-07-21T12:57:25.771576Z","shell.execute_reply":"2022-07-21T12:57:25.902040Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"위 table을 참고하여 남자, 여자가 쓰는 initial을 구분해보고자 한다. replace 메소드를 사용하면, 특정 데이터 값을 1대 1 대응시켜 원하는 값으로 치환해 줄 수 있다.","metadata":{}},{"cell_type":"code","source":"df_train['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)\n\ndf_test['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:25.904829Z","iopub.execute_input":"2022-07-21T12:57:25.905524Z","iopub.status.idle":"2022-07-21T12:57:25.917715Z","shell.execute_reply.started":"2022-07-21T12:57:25.905489Z","shell.execute_reply":"2022-07-21T12:57:25.916815Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_train.groupby('Initial').mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:25.919040Z","iopub.execute_input":"2022-07-21T12:57:25.919736Z","iopub.status.idle":"2022-07-21T12:57:25.948284Z","shell.execute_reply.started":"2022-07-21T12:57:25.919699Z","shell.execute_reply":"2022-07-21T12:57:25.947126Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"여성과 관계있는 Miss, Mr, Mrs가 생존율이 높은 것을 확인할 수 있다.","metadata":{}},{"cell_type":"code","source":"df_train.groupby('Initial')['Survived'].mean().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:25.949770Z","iopub.execute_input":"2022-07-21T12:57:25.950070Z","iopub.status.idle":"2022-07-21T12:57:26.193560Z","shell.execute_reply.started":"2022-07-21T12:57:25.950042Z","shell.execute_reply":"2022-07-21T12:57:26.192445Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"이제 본격적으로 Null을 채울 건데, 우선 null data를 채우는 방법은 정말 많이 존재한다.\nstatistics를 활용하는 방법도 있고, null data가 없는 데이터를 기반으로 새로운 머신러닝 알고리즘을 만들어 예측해서 채워넣는 방법도 있다.\n여기서는 statistics를 활용하는 방법을 사용할 것이다.\n\n여기서 statistics는 train data의 것을 의미한다. 우리는 언제나 test를 unseen으로 둔 상태로 둬야 하며, \ntrain에서 얻은 statistics를 기반으로 test의 null data를 채워줘야 한다.","metadata":{}},{"cell_type":"code","source":"df_train.groupby('Initial').mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.194997Z","iopub.execute_input":"2022-07-21T12:57:26.195823Z","iopub.status.idle":"2022-07-21T12:57:26.218785Z","shell.execute_reply.started":"2022-07-21T12:57:26.195782Z","shell.execute_reply":"2022-07-21T12:57:26.217780Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Age의 평균을 이용해 Null data를 채우도록 해보자.\npandas dataframe을 다룰 땐 boolean array를 이용해 indexing하는 방법을 쓰면 된다.\n아래 코드 첫 줄을 해석해 보자면, isnull() 이면서 Initial이 Mr인 조건을 만족하는 row(탑승객)의 'Age'의 값을 33으로 치환한다는 뜻이다.\nloc + boolean + column을 사용해 값을 치환하는 방법은 자주 쓰이므로 꼭 익숙해져야 한다.","metadata":{}},{"cell_type":"code","source":"df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mr'),'Age'] = 33\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mrs'),'Age'] = 36\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Master'),'Age'] = 5\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Miss'),'Age'] = 22\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Other'),'Age'] = 46\n\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mr'),'Age'] = 33\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mrs'),'Age'] = 36\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Master'),'Age'] = 5\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Miss'),'Age'] = 22\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Other'),'Age'] = 46","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.222778Z","iopub.execute_input":"2022-07-21T12:57:26.223419Z","iopub.status.idle":"2022-07-21T12:57:26.244537Z","shell.execute_reply.started":"2022-07-21T12:57:26.223356Z","shell.execute_reply":"2022-07-21T12:57:26.243155Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Null 값들이 모두 제거됐는지 확인하는 구문.\ndf_train.Age.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.246992Z","iopub.execute_input":"2022-07-21T12:57:26.247306Z","iopub.status.idle":"2022-07-21T12:57:26.262280Z","shell.execute_reply.started":"2022-07-21T12:57:26.247277Z","shell.execute_reply":"2022-07-21T12:57:26.261014Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df_test.Age.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.263995Z","iopub.execute_input":"2022-07-21T12:57:26.264679Z","iopub.status.idle":"2022-07-21T12:57:26.272911Z","shell.execute_reply.started":"2022-07-21T12:57:26.264634Z","shell.execute_reply":"2022-07-21T12:57:26.271601Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"여기선 간단하게 Null을 채웠지만, 좀 더 다양한 방법을 쓴 예시들이 다른 커널에 존재한다. 확인차 df_train.Age와 df_test.Age의 Null Data가 모두 사라졌는지를 나타내는 구문을 통해 확인해 보니 False라고 뜨면서 이제 Null Data가 모두 사라졌다는 것도 알게 되었다.","metadata":{}},{"cell_type":"markdown","source":"#### 3.1.2 Fill Null in Embarked","metadata":{}},{"cell_type":"code","source":"print('Embarked has ', sum(df_train['Embarked'].isnull()), 'Null Values')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.274846Z","iopub.execute_input":"2022-07-21T12:57:26.275485Z","iopub.status.idle":"2022-07-21T12:57:26.286310Z","shell.execute_reply.started":"2022-07-21T12:57:26.275437Z","shell.execute_reply":"2022-07-21T12:57:26.285101Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Embarked 는 Null value 가 2개이고, S에서 가장 많은 탑승객이 있었으므로, 간단하게 Null을 S로 채우고자 한다. 가장 많이 탑승했던 S로 채우는 게 가장 속 편할 것이다.\ndataframe 의 fillna method 를 이용하면 쉽게 채울 수 있다. 여기서 inplace=True 로 하면 df_train 에 fillna 를 실제로 적용한다.","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].fillna('S', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.288436Z","iopub.execute_input":"2022-07-21T12:57:26.289236Z","iopub.status.idle":"2022-07-21T12:57:26.299254Z","shell.execute_reply.started":"2022-07-21T12:57:26.289188Z","shell.execute_reply":"2022-07-21T12:57:26.298023Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_train.Embarked.isnull().any()       # 이제 Embarked 컬럼에도 Null Data가 모두 채워졌다.","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.301186Z","iopub.execute_input":"2022-07-21T12:57:26.301626Z","iopub.status.idle":"2022-07-21T12:57:26.318114Z","shell.execute_reply.started":"2022-07-21T12:57:26.301583Z","shell.execute_reply":"2022-07-21T12:57:26.316597Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Change Age(continuous to categorical)","metadata":{}},{"cell_type":"markdown","source":"나이는 현재 continuous feature이다. 이대로 써도 모델을 세울 수 있지 않느냐 하겠지만 Age를 몇 개의 group으로 나누어 카테고리화 시키는 것이 모델을 세울 때 조금 더 쉽게 할 수 있다. Continuous를 categorical로 바꾸면 자칫 정보 손실이 생길 수도 있지만, 본 튜토리얼에서는 다양한 방법을 소개하는 것이 목적이므로 일단 카테고리를 바꾸는 작업을 진행해 보고자 한다.  \n\n방법은 여러가지가 있는데, loc 를 사용하여 직접해줄 수 있고, 아니면 apply 를 사용해 함수를 넣어줄 수도 있다.\n첫번째로 loc를 사용한 방법이다. loc는 DataFrame index를 활용함으로써 행과 열을 지정하여 data를 획득하는 구문이다. loc는 자주쓰게 되므로 그 사용법을 숙지하시면 좋다. 나이는 10살 간격으로 나눈다.\n\n","metadata":{}},{"cell_type":"code","source":"df_train['Age_cat'] = 0\ndf_train.loc[df_train['Age'] < 10, 'Age_cat'] = 0\ndf_train.loc[(10 <= df_train['Age']) & (df_train['Age'] < 20), 'Age_cat'] = 1\ndf_train.loc[(20 <= df_train['Age']) & (df_train['Age'] < 30), 'Age_cat'] = 2\ndf_train.loc[(30 <= df_train['Age']) & (df_train['Age'] < 40), 'Age_cat'] = 3\ndf_train.loc[(40 <= df_train['Age']) & (df_train['Age'] < 50), 'Age_cat'] = 4\ndf_train.loc[(50 <= df_train['Age']) & (df_train['Age'] < 60), 'Age_cat'] = 5\ndf_train.loc[(60 <= df_train['Age']) & (df_train['Age'] < 70), 'Age_cat'] = 6\ndf_train.loc[70 <= df_train['Age'], 'Age_cat'] = 7\n\ndf_test['Age_cat'] = 0\ndf_test.loc[df_test['Age'] < 10, 'Age_cat'] = 0\ndf_test.loc[(10 <= df_test['Age']) & (df_test['Age'] < 20), 'Age_cat'] = 1\ndf_test.loc[(20 <= df_test['Age']) & (df_test['Age'] < 30), 'Age_cat'] = 2\ndf_test.loc[(30 <= df_test['Age']) & (df_test['Age'] < 40), 'Age_cat'] = 3\ndf_test.loc[(40 <= df_test['Age']) & (df_test['Age'] < 50), 'Age_cat'] = 4\ndf_test.loc[(50 <= df_test['Age']) & (df_test['Age'] < 60), 'Age_cat'] = 5\ndf_test.loc[(60 <= df_test['Age']) & (df_test['Age'] < 70), 'Age_cat'] = 6\ndf_test.loc[70 <= df_test['Age'], 'Age_cat'] = 7","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.320417Z","iopub.execute_input":"2022-07-21T12:57:26.321218Z","iopub.status.idle":"2022-07-21T12:57:26.355095Z","shell.execute_reply.started":"2022-07-21T12:57:26.321172Z","shell.execute_reply":"2022-07-21T12:57:26.353684Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"두번째로 간단한 함수를 만들어 apply 메소드에 넣어주는 방법이다.  \nif와 elif를 구간에 맞게끔 반복 작성하는 것이 포인트이다.  \n위의 loc를 썼을 때보다 훨씬 구문이 간단하다.  ","metadata":{}},{"cell_type":"code","source":"def category_age(x):\n    if x < 10:\n        return 0\n    elif x < 20:\n        return 1\n    elif x < 30:\n        return 2\n    elif x < 40:\n        return 3\n    elif x < 50:\n        return 4\n    elif x < 60:\n        return 5\n    elif x < 70:\n        return 6\n    else:\n        return 7    \n    \ndf_train['Age_cat_2'] = df_train['Age'].apply(category_age)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.356582Z","iopub.execute_input":"2022-07-21T12:57:26.357437Z","iopub.status.idle":"2022-07-21T12:57:26.376229Z","shell.execute_reply.started":"2022-07-21T12:57:26.357384Z","shell.execute_reply":"2022-07-21T12:57:26.375245Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"두가지 방법이 잘 적용됬다면, 둘다 같은 결과가 나와야 한다.  \n이를 확인하기 위해 Series 간 boolean 비교 후 all() 메소드를 확인해 보자.  \nall() 메소드는 모든 값이 True면 True, 하나라도 False가 있으면 False를 준다.","metadata":{}},{"cell_type":"code","source":"print('1번 방법, 2번 방법 둘다 같은 결과를 내면 True 줘야함 -> ', (df_train['Age_cat'] == df_train['Age_cat_2']).all())","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.377771Z","iopub.execute_input":"2022-07-21T12:57:26.378400Z","iopub.status.idle":"2022-07-21T12:57:26.387343Z","shell.execute_reply.started":"2022-07-21T12:57:26.378344Z","shell.execute_reply":"2022-07-21T12:57:26.385934Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"보시다시피 True이다. 둘 중 편한 걸 선택하시면 된다.\n이제 중복되는 Age_cat 컬럼과 원래 컬럼 Age를 제거한다. 제거를 할 때는 drop 메서드를 활용한다.","metadata":{}},{"cell_type":"code","source":"df_train.drop(['Age', 'Age_cat_2'], axis=1, inplace=True)\ndf_test.drop(['Age'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.389189Z","iopub.execute_input":"2022-07-21T12:57:26.390593Z","iopub.status.idle":"2022-07-21T12:57:26.402446Z","shell.execute_reply.started":"2022-07-21T12:57:26.390536Z","shell.execute_reply":"2022-07-21T12:57:26.401464Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### 3.3. Change Initial, Embarked and Sex(string to numerical)","metadata":{}},{"cell_type":"markdown","source":"현재 Initial 은 Mr, Mrs, Miss, Master, Other 총 5개로 이루어져 있다. 이런 문자 형태의 카테고리로 표현되어져 있는 데이터를 모델에 인풋으로 넣어줄 때 우리가 해야할 것은 먼저 컴퓨터가 인식할 수 있도록 수치화 시켜야 한다. map method 를 가지고 간단히 할 수 있다. 사전 순서대로 정리하여 mapping한다.","metadata":{}},{"cell_type":"code","source":"df_train['Initial'] = df_train['Initial'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4})\ndf_test['Initial'] = df_test['Initial'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4})","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.404434Z","iopub.execute_input":"2022-07-21T12:57:26.405220Z","iopub.status.idle":"2022-07-21T12:57:26.415907Z","shell.execute_reply.started":"2022-07-21T12:57:26.405159Z","shell.execute_reply":"2022-07-21T12:57:26.414883Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Embarked 역시 C, Q, S로 이루어져 있으니, map을 이용해 바꾸자.\n그러기 앞서서, 특정 column에 어떤 값들이 있는 지 확인해보는 방법을 잠깐 살펴보자면, 간단히 unique() 메소드를 쓰거나, value_counts()를 써서 count까지 보는 방법이 있긴 하다.","metadata":{}},{"cell_type":"code","source":"# unique 메서드는 지정한 열에서 고유한 값을 추출해내는 기능을 한다.\n# 즉 Embarked 열의 고유한 값인 S, C, Q를 추출해 내는 기능을 수행하고 이를 결과로써 확인 가능하다.\ndf_train['Embarked'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.417973Z","iopub.execute_input":"2022-07-21T12:57:26.418732Z","iopub.status.idle":"2022-07-21T12:57:26.430631Z","shell.execute_reply.started":"2022-07-21T12:57:26.418673Z","shell.execute_reply":"2022-07-21T12:57:26.429257Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#  value_count 메서드를 이용해 S, C, Q에서 각각 몇 명이 탑승했는지 직접 카운팅이 가능하다.\ndf_train['Embarked'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.432203Z","iopub.execute_input":"2022-07-21T12:57:26.433423Z","iopub.status.idle":"2022-07-21T12:57:26.457723Z","shell.execute_reply.started":"2022-07-21T12:57:26.433349Z","shell.execute_reply":"2022-07-21T12:57:26.456408Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df_train['Embarked'] = df_train['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\ndf_test['Embarked'] = df_test['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.458993Z","iopub.execute_input":"2022-07-21T12:57:26.459524Z","iopub.status.idle":"2022-07-21T12:57:26.470240Z","shell.execute_reply.started":"2022-07-21T12:57:26.459489Z","shell.execute_reply":"2022-07-21T12:57:26.469219Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"map 기능을 사용하여 훈련 세트와 테스트 세트의 C는 0으로, Q는 1로, S는 2로 바꾸는 과정이 이루어졌다.  \n이 상태에서 Null이 사라졌는지도 확인해보자. Embarked Column만 가져온 것은 하나의 pandas의 Series 객체이므로, isnull() 메서드를 사용해 Series의 값들이 null인지 아닌지에 대한 boolean 값을 얻을 수 있다. 그리고 이것에 any()를 사용해, True가 단 하나라도 있을 시, 즉 Null이 한 개라도 있을 시 True로 반환하며 Null Data가 전혀 없다면 False로 반환한다. 우리는 이미 Embarked 열에 있던 2개의 Null data를 가장 많았던 S로 바꿨기 때문에 null이 없어야 하고 아래 구문을 실행할 시 False로 나와야 할 것이다.","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.471579Z","iopub.execute_input":"2022-07-21T12:57:26.472318Z","iopub.status.idle":"2022-07-21T12:57:26.493881Z","shell.execute_reply.started":"2022-07-21T12:57:26.472256Z","shell.execute_reply":"2022-07-21T12:57:26.491924Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df_train['Sex'] = df_train['Sex'].map({'female': 0, 'male': 1})\ndf_test['Sex'] = df_test['Sex'].map({'female': 0, 'male': 1})","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.495725Z","iopub.execute_input":"2022-07-21T12:57:26.496544Z","iopub.status.idle":"2022-07-21T12:57:26.510053Z","shell.execute_reply.started":"2022-07-21T12:57:26.496496Z","shell.execute_reply":"2022-07-21T12:57:26.508784Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"위 구문은 Sex도 Male, Female로 이루어져 있는 관계로, map을 이용해 0과 1로 바꾸는 작업에 대한 구문이었다.  \n이제 각 feature 간의 상관관계를 한번 보려고 한다. 두 변수간의 상관관계를 구하게 되면 -1부터 1 사이의 값을 얻을 수 있다. -1로 가까이 갈수록 음의 상관관계를 갖게 되며, 1로 갈수록 양의 상관관계를 갖게 된다. 그리고 0으로 가까이 갈수록 상관관계가 전혀 없다는 뜻이다.  \n구하는 수식을 아래와 같다.\n\n$r_xy = \\frac{Cov(x,y)}{S_xS_y} = \\frac{\\frac{1}{n-1}\\displaystyle\\sum_{i=1}^{n}{(x_i - x\\bar)(y_i - y\\bar)}}{S_xS_y}$  \n\n우리는 여러 feature를 가지고 있으니 이를 하나의 matrix 형태로 보면 편할 텐데, 이를 heatmap plot의 형태로 그려보고자 한다. 이는 dataframe의 corr() 메소드와 seaborn을 가지고 편리하게 할 수 있다.","metadata":{}},{"cell_type":"code","source":"heatmap_data = df_train[['Survived', 'Pclass', 'Sex', 'Fare', 'Embarked', 'FamilySize', 'Initial', 'Age_cat']] \n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14, 12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(heatmap_data.astype(float).corr(), linewidths=0.1, vmax=1.0,\n           square=True, cmap=colormap, linecolor='white', annot=True, annot_kws={\"size\": 16})\n\ndel heatmap_data","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:26.512358Z","iopub.execute_input":"2022-07-21T12:57:26.513443Z","iopub.status.idle":"2022-07-21T12:57:27.164607Z","shell.execute_reply.started":"2022-07-21T12:57:26.513395Z","shell.execute_reply":"2022-07-21T12:57:27.163410Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"우리가 EDA에서 살펴봤듯, Sex와 Pclass가 Survived에 상곤관계가 어느 정도 있는 것 같다고 짐작해 볼수 있다. 그리고 생각보다 fare와 Embarked도 상관관계가 있음을 알 수 있다.  \n(Sex와 Survived : -0.54, Pclass와 Survived : -0.34, fare와 Embarked : -0.2)  \n하지만 우리는 여기서 서로 강한 상관관계를 가지는 feature는 없다는 것 또한 알게 되었고, 이는 곧 우리가 모델을 학습시킬 때 불필요한(redundant, superfluous) feature가 없다는 것을 의미한다. 1 또는 -1의 상관관계를 가진 feature A,B가 있다면, 우리가 얻을 수 있는 정보는 사실 하나일 것이다.  \n이제 실제로 모델을 학습시키기 앞서서 data preprocessing(데이터 전처리)을 진행해 보고자 한다.","metadata":{}},{"cell_type":"markdown","source":"### 3.4. One-hot encoding on Initial and Embarked","metadata":{}},{"cell_type":"markdown","source":"수치화시킨 카테고리 데이터를 그대로 넣어도 되지만, 모델의 성능을 높이기 위해 one-hot encoding을 해줄 수 있다. One-hot encoding은 위 카테고리를 아래와 같이 (0, 1) 로 이루어진 5차원의 벡터로 나타내는 것을 말하며, 수치화는 간단히 Master == 0, Miss == 1, Mr == 2, Mrs == 3, Other == 4 로 매핑해주는 것을 말한다.  \n이 작업을 직접 코딩할 수도 있겠지만, pandas의 get_dummies를 사용해 쉽게 해결할 수 있다. 총 5개의 카테고리이니, one-hot encoding을 하고 나면 새로운 5개의 column이 생겨난다. 우선, Initial을 prefix로 두어 구분이 쉽게 만들어준다.","metadata":{}},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train, columns=['Initial'], prefix='Initial')\ndf_test = pd.get_dummies(df_test, columns=['Initial'], prefix='Initial')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:27.165915Z","iopub.execute_input":"2022-07-21T12:57:27.166303Z","iopub.status.idle":"2022-07-21T12:57:27.196936Z","shell.execute_reply.started":"2022-07-21T12:57:27.166264Z","shell.execute_reply":"2022-07-21T12:57:27.193832Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:27.207561Z","iopub.execute_input":"2022-07-21T12:57:27.208511Z","iopub.status.idle":"2022-07-21T12:57:27.238178Z","shell.execute_reply.started":"2022-07-21T12:57:27.208463Z","shell.execute_reply":"2022-07-21T12:57:27.236948Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"위 내용을 실행한 후 표의 맨 우측을 보면 우리가 만들려고 했던 one-hot encoded columns가 생성되어 있는 것을 확인할 수 있다.\nEmbarked에도 적용해 보고, Initial 때와 마찬가지로 one-hot encoding을 사용해 표현해 보자.","metadata":{}},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train, columns=['Embarked'], prefix='Embarked')\ndf_test = pd.get_dummies(df_test, columns=['Embarked'], prefix='Embarked')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:27.239944Z","iopub.execute_input":"2022-07-21T12:57:27.240678Z","iopub.status.idle":"2022-07-21T12:57:27.271238Z","shell.execute_reply.started":"2022-07-21T12:57:27.240620Z","shell.execute_reply":"2022-07-21T12:57:27.269883Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"아주 쉽게 one-hot encoding을 적용할 수 있었다.  \nsklearn(사이킷런)으로 Labelencoder + OneHotencoder 이용해도 one-hot encoding이 가능하다.  \n가끔 category가 100개가 넘어가는 경우가 있는데, 이때 one-hot encoding을 사용하면 column이 100개가 생겨, 학습 시 매우 버거울 경우가 있다. 이런 경우는 다른 방법을 사용하기도 한다.","metadata":{}},{"cell_type":"markdown","source":"### 3.5. Drop columns","metadata":{}},{"cell_type":"markdown","source":"필요한 Column만 남기도 다 지우는 작업을 한다. drop 메서드를 가져와서 이를 수행할 수 있다.\n\nPassengerId : 카테고리화 될 수 없기 때문에 필요없다.  \nName : 카테고리 자료형으로 변환할 수 없으므로 필요없다.  \nSibSp와 Parch : FamilySize로 카테고리화를 이미 했기 때문에 필요없다.\nTicket : 이름과 마찬가지로 카테고리화 될 수 없는 무작위 문자열이므로 필요없다.   \nCabin : NaN 값이 너무 많고, 많은 승객에 따라 cabin 값이 많다. 그렇기 때문에 필요없다.  ","metadata":{}},{"cell_type":"code","source":"df_train.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)\ndf_test.drop(['PassengerId', 'Name',  'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:27.272986Z","iopub.execute_input":"2022-07-21T12:57:27.273473Z","iopub.status.idle":"2022-07-21T12:57:27.283980Z","shell.execute_reply.started":"2022-07-21T12:57:27.273425Z","shell.execute_reply":"2022-07-21T12:57:27.282773Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:27.285394Z","iopub.execute_input":"2022-07-21T12:57:27.286578Z","iopub.status.idle":"2022-07-21T12:57:27.303983Z","shell.execute_reply.started":"2022-07-21T12:57:27.286528Z","shell.execute_reply":"2022-07-21T12:57:27.303059Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:27.305353Z","iopub.execute_input":"2022-07-21T12:57:27.305932Z","iopub.status.idle":"2022-07-21T12:57:27.325855Z","shell.execute_reply.started":"2022-07-21T12:57:27.305898Z","shell.execute_reply":"2022-07-21T12:57:27.324923Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"train과 test의 상위 5개의 데이터와 컬럼을 확인해 보면 Survived feature(target class)를 빼면 train, test 둘다 같은 columns 를 가진 걸 알 수 있다.","metadata":{}},{"cell_type":"markdown","source":"# 4. Building machine learning model and prediction using the trained model","metadata":{}},{"cell_type":"markdown","source":"데이터 준비가 모두 이루어졌으니, sklearn을 사용해 본격적으로 머신러닝 모델을 만들어 보자.","metadata":{}},{"cell_type":"code","source":"# 머신러닝 모델을 만들기 위한 패키지를 모두 가져오는 작업\nfrom sklearn.ensemble import RandomForestClassifier     # 유명한 랜덤 포레스트. \nfrom sklearn import metrics                             # 모델의 평가를 위해서 씁니다\nfrom sklearn.model_selection import train_test_split    # train과 test를 분할하는데 쓰이는 함수.","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:57:49.054231Z","iopub.execute_input":"2022-07-21T12:57:49.054744Z","iopub.status.idle":"2022-07-21T12:57:49.403162Z","shell.execute_reply.started":"2022-07-21T12:57:49.054704Z","shell.execute_reply":"2022-07-21T12:57:49.402165Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Sklearn은 머신러닝의 처음부터 끝까지가 다 있다고 할 수 있다. 특성 엔지니어링과 데이터 전처리, 지도 학습 및 비지도 학습 알고리즘, 모델 평가, 파이프라인 등 머신러닝에 관련된 모든 작업들이 손쉬운 인터페이스로 구현되어 있다. 데이터 분석 + 머신러닝을 하고싶다면, 이 라이브러리는 반드시 숙지해야 한다.\n파이썬 라이브러리를 활용한 머신러닝(Introduction to machine larning with Python)책을 사서 공부를 하면 크게 도움이 될 거라고 한다.  \n\n지금 타이타닉 문제는 target class로 생존 여부(survived)가 있으며, target class 는 0, 1로 이루어져 있으므로 둘 중에 하나를 골라내는 이진 분류(binary classfication) 문제이다.\n우리가 지금 가지고 있는 train set 의 survived를 제외한 input 을 가지고 모델을 최적화시켜서 각 샘플(탑승객)의 생존유무를 판단하는 모델을 만들어 내는 것이 목표이다.\n그 후 모델이 학습하지 않았던 test set 을 input 으로 주어서 test set 의 각 샘플(탑승객)의 생존 유무를 예측한다.","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Preparation - Split dataset into train, valid, test set","metadata":{}},{"cell_type":"markdown","source":"가장 먼저, 학습에 쓰일 데이터와 target label 즉 생존유무를 분리해 내는 과정으로써 drop을 사용하여 코드를 구성한다.","metadata":{}},{"cell_type":"code","source":"X_train = df_train.drop('Survived', axis=1).values\ntarget_label = df_train['Survived'].values\nX_test = df_test.values","metadata":{"execution":{"iopub.status.busy":"2022-07-21T12:58:23.979654Z","iopub.execute_input":"2022-07-21T12:58:23.980051Z","iopub.status.idle":"2022-07-21T12:58:23.987237Z","shell.execute_reply.started":"2022-07-21T12:58:23.980019Z","shell.execute_reply":"2022-07-21T12:58:23.986435Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"* 보통 train, test만 언급되지만, 실제 좋은 모델을 만들기 위해서 우리는 valid set을 따로 만들어 모델 평가를 해 볼 것이다.\n\n* 마치 축구대포팀이 팀훈련(train)을 하고 바로 월드컵(test)으로 나가는 것이 아니라, 팀훈련(train)을 한 다음 평가전(valid)을 거쳐 팀의 훈련 정도를 확인하고 월드컵(test)에 나가는 것과 비슷한 이치이다.  \n\n* 훈련 세트와 테스트 세트를 분리하는 이유는 연습 문제와 시험 문제가 달라야 올바르게 학생을 평가할 수 있듯이 모델을 평가할 때도 훈련 때 사용한 데이터가 아닌 훈련 때 사용하지 않은 데이터를  평가를 해야 올바르게 평가가 되기 때문이다. 즉 모델을 정확히 검증하기 위해 거치는 과정인 셈이다. \n\n* 훈련 세트와 테스트 세트를 분리하는 것은 train_test_split을 사용하면 된다. 앞으로 모델링을 하면서 훈련 세트와 테스트 세트를 분리하는 과정을 필히 거치게 되므로, 이 구문은 지겹도록 보게 될 것으로 보인다.","metadata":{}},{"cell_type":"code","source":"X_tr, X_vld, y_tr, y_vld = train_test_split(X_train, target_label, test_size=0.3, random_state=2018)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:18:02.873226Z","iopub.execute_input":"2022-07-21T13:18:02.873814Z","iopub.status.idle":"2022-07-21T13:18:02.883276Z","shell.execute_reply.started":"2022-07-21T13:18:02.873767Z","shell.execute_reply":"2022-07-21T13:18:02.882072Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"* sklearn 에서는 여러 머신러닝 알고리즘을 지원해 준다. 열거하기엔 너무 많으므로, 직접 documentation에 들어가 보시길 추천합니다.  \n\n* http://scikit-learn.org/stable/supervised_learning.html#supervised-learning 여기에 들어가서 확인해보자. 사이킷런 공식 사이트인데 굉장히 많은 알고리즘이 지원됨을 알 수 있다. 우리는 머신러닝을 배울 때 이 사이트에서 많은 부분을 활용할 것으로 기대된다.\n\n* 본 튜토리얼에서는 랜덤포레스트 모델을 사용하고자 한다. 랜덤포레스트는 결정 트리 기반 모델이며, 여러 결정 트리들을 앙상블한 모델이라고 한다.\n\n* 각 머신러닝 알고리즘에는 여러 파라미터들이 있다. 랜덤포레스트분류기도 n_estimators, max_features, max_depth, min_samples_split, min_samples_leaf 등 여러 파라미터들이 존재한다. 이것들이 어떻게 세팅되냐에 따라 같은 데이터셋이라 하더라도 모델의 성능이 달라지게 된다.  \n\n* 파라미터 튜닝은 시간, 경험, 알고리즘에 대한 이해 등이 필요하고, 결국 많이 써봐야 모델도 잘 세울 수 있다. 캐글 필사를 하는 이유가 바로 많이 써봄으로써 모델을 세우는 데 익숙해질 수 있기 때문이고 작성을 하고 있는 지금도 조금씩 체감을 하고 있다. 여러 데이터셋을 가지고 모델을 이리저리 써봐야 튜닝하는 감이 생길테니까!\n\n* 일단 지금은 튜토리얼이니 파라미터 튜닝은 잠시 제쳐두기로 하고, 기본 default 세팅으로 진행코자 한다. 모델 객체를 만들고, fit 메서드를 활용해 모델을 학습시킨다. fit 역시 모델을 학습할 때 반드시 포함이 되는 구문이니 잘 익혀 둬야 겠다고 생각했다.\n\n* 그런 후 valid set input 을 넣어주어 예측값(X_vld sample(탑승객)의 생존여부)를 얻어내면 된다.","metadata":{}},{"cell_type":"markdown","source":"### 4.2 Model generation and prediction","metadata":{}},{"cell_type":"code","source":"model = RandomForestClassifier()\nmodel.fit(X_tr, y_tr)\nprediction = model.predict(X_vld)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:37:36.107320Z","iopub.execute_input":"2022-07-21T13:37:36.107812Z","iopub.status.idle":"2022-07-21T13:37:36.334925Z","shell.execute_reply.started":"2022-07-21T13:37:36.107774Z","shell.execute_reply":"2022-07-21T13:37:36.333927Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"* 단 세 줄만으로 모델을 세우고 예측까지 해보는 코드를 작성했다. 단, 작성할 때 변수 이름에 유의해야 된다는 점!! fit 뒤에는 훈련 tr 혹은 train이 들어간 변수가 주로 들어가고, predict 뒤로는 test 혹은 valid, vld와 같은 단어가 포함된 경우가 많다는 점이 있다. 이 점은 코드를 작성할 때 참고할 만한 내용이라고 생각했다.\n\n* 성능 모델을 확인하기 위해 다음 코드를 작성해서 결과를 확인해 보자.","metadata":{}},{"cell_type":"code","source":"print('총 {}명 중 {:.2f}% 정확도로 생존을 맞춤'.format(y_vld.shape[0], 100 * metrics.accuracy_score(prediction, y_vld)))","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:37:33.029156Z","iopub.execute_input":"2022-07-21T13:37:33.029654Z","iopub.status.idle":"2022-07-21T13:37:33.036753Z","shell.execute_reply.started":"2022-07-21T13:37:33.029609Z","shell.execute_reply":"2022-07-21T13:37:33.035700Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"아무런 파라미터 튜닝도 없이 생으로 모델 검증을 했음에도 82%의 정확도로 생존을 맞혔음을 알 수 있다. 결과값은 코드를 돌릴 때마다 80% 대에서 약간의 차이는 있을 수 있다는 점도 밝혀냈다.","metadata":{}},{"cell_type":"markdown","source":"### 4.3 Feature importance","metadata":{}},{"cell_type":"markdown","source":"* 학습된 모델은 feature importance를 가지게 되는데, 우리는 이것을 확인하여 지금 만든 모델이 어떤 feature에 영향을 많이 받았는 지 확인할 수 있다.\n\n* 쉽게 말해, $10 = 4x_1 + 2x_2 + 1*x_3$ 을 생각하면, 우리는 $x_1$이 결과값(10)에 큰 영향을 준다고 생각 할 수 있다. feature importance 는 4, 2, 1 을 이야기하며, $x_1$이 가장 큰 값(4)를 가지므로, 이 모델에 가장 큰 영향을 미친다고 말할 수 있게 되는 것이다.\n\n* 학습된 모델은 기본적으로 feature importances를 가지고 있어서 쉽게 그 수치를 얻을 수 있기는 하다. pandas series 를 이용하면 쉽게 sorting(정렬)을 하여 그래프를 그릴 수 있습니다.","metadata":{}},{"cell_type":"code","source":"from pandas import Series\n\nfeature_importance = model.feature_importances_\nSeries_feat_imp = Series(feature_importance, index=df_test.columns)\nplt.figure(figsize=(8, 8))\n\nSeries_feat_imp.sort_values(ascending=True).plot.barh()\nplt.xlabel('Feature importance')\nplt.ylabel('Feature')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:38:24.637576Z","iopub.execute_input":"2022-07-21T13:38:24.637974Z","iopub.status.idle":"2022-07-21T13:38:24.887599Z","shell.execute_reply.started":"2022-07-21T13:38:24.637942Z","shell.execute_reply":"2022-07-21T13:38:24.886443Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"* 우리가 얻은 모델에서는 Fare(요금)가 가장 큰 영향력을 가지며, 그 뒤로 Initial_2, Age_cat, Pclass가 차례로 중요도를 가진다.\n\n* 사실 feature importance는 지금 모델에서의 importance를 나타낸다. 만약 다른 모델을 사용하게 된다면 feature importance가 다르게 나올 수 있다.\n\n* 이 feature importance를 보고 실제로 Fare가 중요한 feature일 수 있다고 판단을 내릴 수는 있지만, 이것은 결국 모델에 귀속되는 하나의 결론이므로 통계적으로 좀 더 살펴보긴 해야할 것이다. 결국 절대적인 개념이 아닌 상대적인 개념이라는 것이다.\n\n* featuure importanc 를 가지고 좀 더 정확도가 높은 모델을 얻기 위해 feature selection을 할 수도 있고, 좀 더 빠른 모델을 위해 feature 제거를 할 수 있다.","metadata":{}},{"cell_type":"markdown","source":"### 4.4 Prediction on Test set","metadata":{}},{"cell_type":"code","source":"이제 모델이 학습하지 않았던(보지 않았던) 테스트셋을 모델에 주어서, 생존여부를 예측해보고자 한다. 이 결과는 실제로 submission(제출용) 이므로 결과는\nleaderboard에서 확인할 수 있다. 캐글에서 준 파일, gender_submission.csv 파일을 읽어서 제출 준비를 하고자 한다.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/titanic/gender_submission.csv')\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:47:21.790017Z","iopub.execute_input":"2022-07-21T13:47:21.790460Z","iopub.status.idle":"2022-07-21T13:47:21.808271Z","shell.execute_reply.started":"2022-07-21T13:47:21.790406Z","shell.execute_reply":"2022-07-21T13:47:21.807160Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"이제 testset에 대하여 예측을 하고, 결과를 csv 파일로 저장하는 과정이다.","metadata":{}},{"cell_type":"code","source":"prediction = model.predict(X_test)\nsubmission['Survived'] = prediction\nsubmission.to_csv('./my_first_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T13:47:40.819818Z","iopub.execute_input":"2022-07-21T13:47:40.820308Z","iopub.status.idle":"2022-07-21T13:47:40.851498Z","shell.execute_reply.started":"2022-07-21T13:47:40.820271Z","shell.execute_reply":"2022-07-21T13:47:40.850231Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"이름과 일치하는 해당 파일을 찾은 후 캐글에 제출하면 끝!!","metadata":{}},{"cell_type":"markdown","source":"# 5. 회고","metadata":{}},{"cell_type":"markdown","source":"titanic 예제를 가지고 굉장히 멀리까지 왔는데 앞으로 배울 것이 너무나도 많고 활용 범위가 무궁무진하다고 하니 기대 반 걱정 반이다.\n\n좀 더 참신한 feature engineering, 머신 러닝 모델, hyperparameter tunning, ensembling 등 너무나 많다고 한다. 아직 이게 무슨 개념인지도 모르겠지만 머신 러닝, 딥러닝을 공부하면서 차차 알아갈 것이라고 한다. 포기하지 말고 재미있게 공부하며 성장하는 나 자신을 바라보며 회고를 마치고자 한다!!!","metadata":{}}]}