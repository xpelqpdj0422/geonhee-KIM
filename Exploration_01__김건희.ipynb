{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploration 01 _김건희",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load_digits : 손글씨 분류"
      ],
      "metadata": {
        "id": "APQWLlWblMRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 필요한 모듈 import하기"
      ],
      "metadata": {
        "id": "WezVlggSzm3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn                             # sklearn을 불러온 후\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(sklearn.__version__)          # sklearn 라이브러리 버전 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDIGRyBdzntN",
        "outputId": "9d1228a7-bd0d-4b15-ee3f-4ea639679e3e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits         # digits는 손글씨를 의미한다.\n",
        "# sklearn은 사이킷런의 준말이며 앞으로 작성할 때 이렇게 작성할 것이다.\n",
        "# from A import B 구문을 통해 사이킷런 데이터셋 중 digit에 관한 파일을 로드한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "Waikov9L0AyR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2. 데이터 준비 및 이해하기"
      ],
      "metadata": {
        "id": "_Hhz91qBGhQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits = load_digits()\n",
        "print(dir(digits))\n",
        "# dir()은 객체가 어떤 변수와 메서드를 가지고 있는지 나열한 것이다. 프린트 하게 되면 담고 있는 변수와 메서드가 알파벳 순으로 정렬됨을 알 수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiIqFGjR0vb5",
        "outputId": "5635e706-fd07-4fe4-b19b-f2a59e578203"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Digits의 경우는 data, target, frame, target_names, DESCR, feature_names, frame의 7개의 key를 담고 있음을 알 수 있다."
      ],
      "metadata": {
        "id": "mz4vFfS01BqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits.keys()                # digits dataset이 어떤 정보를 담고 있는지에 대한 key를 불러오는 기능을 한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9DLpaUm1_ek",
        "outputId": "9bfe7f0a-c8e3-4934-9ae9-73013311545b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digits_data = digits.data\n",
        "\n",
        "print(digits_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvpe3S9I5XDT",
        "outputId": "fc071282-6ccd-4c28-cfd0-8ed66aa4fd2d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "shape를 붙여서 배열의 정보를 출력해보니 무려 1797개의 데이터가 64개의 숫자를 담고 있었다. 0번 인덱스의 digit 데이터를 뽑아서 확인해보면!!"
      ],
      "metadata": {
        "id": "sqckbLPc5uP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits_data[0]         # 0번 인덱스의 데이터 색출"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7deAfAh5sjT",
        "outputId": "e2c602df-d961-428c-f0bd-b7d452c32f7e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
              "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
              "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
              "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
              "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "64개의 숫자로 이루어진 array가 출력되었다. 이 데이터셋을 이해하기 위해서는 64개의 숫자가 어떤 의미를 담고 있는지를 이해할 필요가 있다.\n",
        "\n",
        "손글씨 데이터는 이미지 데이터이므로 각 숫자는 pixel값을 의미한 것이다. 길이 64의 숫자 배열은 사실 8 X 8 크기의 이미지를 일렬로 쭉 펴 놓은 것이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "K8KOsO8e8hsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits_label = digits.target                # digits 데이터를 타켓 변수에 저장하는 과정\n",
        "print(digits_label.shape)                   # label의 데이터 형태를 출력해보디 1차원 1797개의 데이터 존재\n",
        "digits_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWRIgeVR6pWQ",
        "outputId": "75e4e3a3-434e-41c8-f317-0bf8c6ebd911"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 8, 9, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 이미지가 어떻게 생겼을지 한 번 확인해 보자. 이미지를 보기 위해서는 matplotlib라는 라이브러리가 필요하다. 또한 이미지를 현재 화면에 보여주기 위해 %matplotlib inline이라는 코드를 추가한다.\n",
        "\n",
        "이미지는 다음과 같이 간단히 확인할 수 있다. 다만, 다만, 일렬로 펴진 64개 데이터를 (8, 8)로 reshape해주는 것을 잊으면 안 된다."
      ],
      "metadata": {
        "id": "kXMGt5gq-LeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt    # 이미지화 데이터 시각화를 돕는 라이브러리. as 뒤에 plt를 적음으로써 matplot 대신 plt로 대신 나타낸다.\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')   # 64개의 데이터를 8,8로 reshape하는 과정을 나타냄.\n",
        "plt.axis('off')         # 여기에서 axis('off')를 붙여주면 좌표가 사라지고 이미지만 보여지게 된다.\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "kLyBlNaJ921f",
        "outputId": "68faa37f-023c-4994-d70a-4d41cbe04438"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0처럼 생긴 이미지가 보이는 것을 확인할 수 있다.\n",
        "\n",
        "여러 개의 이미지를 한번에 확인하기 위해 for 반복문을 활용해 보겠다."
      ],
      "metadata": {
        "id": "GQDzJHcf-J1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  plt.subplot(2,5, i+1)\n",
        "  plt.imshow(digits.data[i].reshape(8,8), cmap='gray')\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "u-0KJFwm_Ua8",
        "outputId": "03dd328e-8066-46fb-d582-b82093abbc4d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAC+CAYAAACWL9wvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAIwUlEQVR4nO3dMVIUXRcG4Dt/fTl8bkDUBYAlOVClMSSYghEhZJCJGURgiIkQm0CsVUAuJWxAcQPCrGD+Fdxztcc5M9T3POlhpnua7rc6eOve3mAwKADk+N+4TwDgv0ToAiQSugCJhC5AIqELkOifaNjr9TpVG1ZXV8P53t5edfbly5fqbGdnpzq7u7trn1jFYDDo/e7fdr0mLRcXF9XZ9PR0dfb27dvq7OzsrPP5/Mk1KWV012VxcbE6Oz09rc6ur687fWdLxr2yvb0dzqPn5/v379XZ/Px8dfbQn5/oGTk+Pq7OVlZWRnA28TXxpguQSOgCJBK6AImELkAioQuQSOgCJAorY11FlZZSSnn69Gl19u+//1Znv379qs5ev34dHvPTp0/hfNzu7++rs4WFhepsaWmpOhumMpZlbm4unJ+fn1dn/X6/OpuZmel6SimiZ6RVudzY2KjOjo6OqrMXL15UZ1FV8yFYX1+vzqL64Dh40wVIJHQBEgldgERCFyCR0AVIJHQBEnWujEX1k6gSVkopz549q86iVZI+f/7c6XxKGX9lrFWN6rry1aTVYf5Ua5Wnm5ub6ixaZSxafW0SfPjwoTrb398PP/v169fqLHp+HnItLFpFrJS4MnZ4eFidDVMtvL297fQ5b7oAiYQuQCKhC5BI6AIkEroAiYQuQCKhC5Coc083WoLx6uoq/GzUJYy0vnfctra2qrPd3d3ws1NTU52OGe0i/BBEHcpS4i5k9NlJX9YyegZaPfdoHnVxo2d2mN2AM0Q93FLivm20G3B0D0XLrZbSfqZrvOkCJBK6AImELkAioQuQSOgCJBK6AIlGUhkb1RJyk155ieonUW2llO7n31rybhJE5xjV7EppL/1Y06oYTbJWpfLRo0fVWbT8aTR79epVeMyM52t5ebk6Ozg4CD97cnLS6Zibm5vV2Zs3bzp9Z4s3XYBEQhcgkdAFSCR0ARIJXYBEQhcgUefKWFQhae3MG4lqYdH3jnu333GJdhmelJ2Co9WYospOS1Qna60Q9ZBFz15U/To6OqrOtre3w2Pu7Oy0T2xI/X6/06yUUtbW1qqz1k7cNdFu08PwpguQSOgCJBK6AImELkAioQuQSOgCJOpcGYtWQmpVxlZXVzvNIvv7+50+x+hFK6wtLi6Gn52dna3OokpPtDHlx48fw2OOe1PLvb29cN5188mXL19WZ5NQuYw2WW2tphfVwqLvjVYnG1Xt0JsuQCKhC5BI6AIkEroAiYQuQCKhC5BI6AIkGklPt7UMXNRDvLq6qs7m5+fbJzahWp2/qBsa7ZIa9VxbOxBniZaYbC27F82jJSOja3Z7exsec9w93dbOu9ESjZGoi7uxsdHpOydF9HxNTU1VZ+N4RrzpAiQSugCJhC5AIqELkEjoAiQSugCJeoPBYNznAPCf4U0XIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2AREIXIJHQBUgkdAESCV2ARP9Ew16vN+jypRcXF+H89va2OltfX+9yyKEMBoPe7/5t12vSEl2z6enp6mxubm4EZ/Nn16SU7tdla2srnEe/fWVlpTqbnZ2tzvr9fnjMmZmZ6uzu7m7k98rh4WE4j3738fFxp++9v79vnldNxvNzenoazqP7ZHFxscshhxJdE2+6AImELkAioQuQSOgCJBK6AImELkCi3mBQb3B0rXdElbBSSnn8+HGXry0/f/6szqKaT0tG5WV5eTmcR5WYd+/eVWe7u7tdTqdpUipjkevr607fG9WLSokrRhn3Sqty2fVej57LYWpVf+uaRL/rx48ff3ZSv+nm5qY6G6aOqTIGMCGELkAioQuQSOgCJBK6AImELkCicJWxrlorFkWVsWgFqK4rcf3OOY1aVPtqaa2w9JC1VtSKRHW5qH40jlWn/kRUhSul+yp90TPQuiatGtvf0HqGI5eXl9XZqKpyXXnTBUgkdAESCV2AREIXIJHQBUgkdAESCV2ARCPp6baWdox2ap2amqrOov7iuHu4La0OYrTEXKu3OemiLuQwPcmuy0JGu+mWEu+om6F1/G/fvlVnUT85ekZaz2yGYc4h+p9GPfdhusFdedMFSCR0ARIJXYBEQhcgkdAFSCR0ARKNpDLWquRENaFoB86Dg4OupzTUEoJ/Q6uaEtVlompUVIeZhBpQKfF5tHZc7Vopi+7BjGUKhzFMjWlhYaE6e/LkSXU2CfdKVGmLKpWllHJ3d1edvX//vjqL7r/Wrstdr5k3XYBEQhcgkdAFSCR0ARIJXYBEQhcg0UgqYy2jqOy06h3j1qqXRFWfqEIU1eieP38eHjNr9bLot7fqhYPBoNNnJ70WFlWVzs/Pw89GO0tHz0FUL2z9H8ZdKWtVC6N51/u8VTNtXbMab7oAiYQuQCKhC5BI6AIkEroAiYQuQKKRVMaWl5fDeb/fr852d3c7HTOqw0yC1maDUfUrqutEFaFWpWUSNrxs1XKie+Xy8vJvn06a6H8a/eZS4msW3Q/Rhpbr6+vhMbs+l1miezm6XtHv7loJa/GmC5BI6AIkEroAiYQuQCKhC5BI6AIkEroAiUbS011aWgrnm5ubnb735OSkOpv0pfxaPd2oXxl1CaPfPend5VLau/2ura1VZ9HusZMuOvfWvRztfBt1fM/Ozqqzce+W3dI6v2hpx2hp1Oj+G1WP3ZsuQCKhC5BI6AIkEroAiYQuQCKhC5CoF+22CsDf5U0XIJHQBUgkdAESCV2AREIXIJHQBUj0f0QvgkQx1W83AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "해상도가 낮긴 하지만 우리는 0부터 9까지의 숫자를 형상화 시켜보았다. target의 데이터도 확인해보자."
      ],
      "metadata": {
        "id": "Bnio38v8_vKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits_label = digits.target\n",
        "print(digits_label.shape)\n",
        "digits_label[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6Gua4pU_5HV",
        "outputId": "bb1ee645-3724-4f8b-e562-1c78640b6f98"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "총 1797개의 데이터가 있는데 0부터 9까지의 숫자로 나타낸 것을 알 수 있다. 바로 각 이미지 데이터가 어떤 숫자를 나타내는지를 담고 있는 데이터이다.\n",
        "\n",
        "각 이미지 데이터가 입력되었을 때 그 이미지가 숫자 몇을 나타내는 이미지인지를 맞추는 분류 모델을 학습시키는 것이 목표라는 것을 알게 되었다. 다만, 이번에는 정확도의 함정을 확인하는 실험이기 때문에 약간의 장치를 넣어볼 것이다.\n",
        "\n",
        "숫자 10개를 모두 분류하는 것이 아니라, 해당 이미지 데이터가 3인지 아닌지를 맞히는 문제로 변형해서 풀어보는 것이다. 즉 입력된 데이터가 3이라면 3을, 3이 아닌 다른 숫자라면 0을 출력하도록 하는 모델을 생각해 보자.\n"
      ],
      "metadata": {
        "id": "MCj4AAVIAODu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_label = [3 if i == 3 else 0 for i in digits_label]\n",
        "from sklearn.metrics import classification_reportnew_label[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBYHBqAC91PO",
        "outputId": "16feeec9-c3c6-4ef4-895d-ea46b43775a4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3. Train, Test 데이터 분리\n",
        "\n",
        "모델 학습용 데이터를 train 데이터라고 하며 test 데이터는 말 그대로 데이터를 토대로 정답을 유추해 내기 위한 데이터이다. \n",
        "X_train, X_test, y_train, y_test를 생성하는 방법을 참고하여 다음과 같이 작성해 보았다. 붓꽃 예제에서 했던 방법과 거의 유사하게 의사결정 나무(decision tree) 모델을 구현해 보겠다."
      ],
      "metadata": {
        "id": "2OuDoW5YK9B0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(digits_data, new_label, test_size=0.2, random_state=15)"
      ],
      "metadata": {
        "id": "zehY9vuEBp7Q"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.4. 다양한 모델로 학습"
      ],
      "metadata": {
        "id": "jq5gyCfRMrrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.1. Decision Tree 사용해보기"
      ],
      "metadata": {
        "id": "9JOXy4MeNDR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(random_state = 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH-BMeEgNAdT",
        "outputId": "8c549606-4550-4c15-fbee-54882d171058"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(random_state=15)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldU9Em_VDidf",
        "outputId": "2441a106-09b8-454d-e2e6-ee673cff6d1f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97       333\n",
            "           3       0.58      0.67      0.62        27\n",
            "\n",
            "    accuracy                           0.94       360\n",
            "   macro avg       0.78      0.81      0.79       360\n",
            "weighted avg       0.94      0.94      0.94       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLjmgjw_Vo0N",
        "outputId": "16916bfa-831a-44b7-a10b-7a6794b57f80"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9388888888888889"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.2 Random Forest 사용해보기\n",
        "\n",
        "from A import B 구문을 활용하여 랜덤 포레스트를 불러들인다.\n"
      ],
      "metadata": {
        "id": "fcOcLWPQNRY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(random_state=32)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIDLJhbANPdx",
        "outputId": "20c6b874-a43c-46f9-e283-81da9924ebc8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       333\n",
            "           3       1.00      0.78      0.88        27\n",
            "\n",
            "    accuracy                           0.98       360\n",
            "   macro avg       0.99      0.89      0.93       360\n",
            "weighted avg       0.98      0.98      0.98       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VymsIN0VryJ",
        "outputId": "291d7670-1a8c-4812-d126-899559dd9f94"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9833333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.3 SVM 사용해 보기\n",
        "\n",
        "SVM을 비롯하여 SGD Classifier 모델, 그리고 Logistic Regression은 코드가 거의 비슷하게 구성이 되어 있어서 어렵지 않게 작성할 수 있다. 구현해 보고자 하는 모델명만 주의해서 작성하면 된다."
      ],
      "metadata": {
        "id": "vvW8hZ0qNyZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "svm_model = svm.SVC()\n",
        "\n",
        "print(svm_model._estimator_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M448iWKdNxf5",
        "outputId": "907e2df0-eb2d-487b-db88-00f4e37c0ee5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM4pEALwOP2f",
        "outputId": "4dc2bc7f-98c0-403b-bdeb-0cf075eaedff"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       333\n",
            "           3       1.00      0.96      0.98        27\n",
            "\n",
            "    accuracy                           1.00       360\n",
            "   macro avg       1.00      0.98      0.99       360\n",
            "weighted avg       1.00      1.00      1.00       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K0_G4N3VwZa",
        "outputId": "8b539db1-f573-4ab4-803c-834a238bd4fc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9833333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.4 SGD Classifier 모델 사용"
      ],
      "metadata": {
        "id": "5LDDZ1MMO-ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier()\n",
        "\n",
        "print(sgd_model._estimator_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "580pPiMWO9fk",
        "outputId": "af0fe5d8-2f8a-4da1-91ed-008fd9cdf4fa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3Lu1X1xQVGv",
        "outputId": "4400cb79-4083-406e-c09b-0aba83b8fc67"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       333\n",
            "           3       0.85      0.85      0.85        27\n",
            "\n",
            "    accuracy                           0.98       360\n",
            "   macro avg       0.92      0.92      0.92       360\n",
            "weighted avg       0.98      0.98      0.98       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHa2MJ57VyYq",
        "outputId": "86b4984a-37fc-4264-95e0-35c511a7b8f2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.5 Logistic Regression 사용하기"
      ],
      "metadata": {
        "id": "w119zN3lQ846"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "print(logistic_model._estimator_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjNy2pReQ3F1",
        "outputId": "00c9e8bb-60fe-4fa0-c628-5c81ebf8310a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prf5SSVuQkLw",
        "outputId": "aafb3130-b78c-40ba-ab52-8b747a6d0a1c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       333\n",
            "           3       0.92      0.85      0.88        27\n",
            "\n",
            "    accuracy                           0.98       360\n",
            "   macro avg       0.95      0.92      0.94       360\n",
            "weighted avg       0.98      0.98      0.98       360\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9tj_FLzV1li",
        "outputId": "d5f3dbb1-ec88-4a6f-d0eb-2b1ca6b036f3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1차 결론 : 다섯가지의 모델을 모두 돌려보니 정확도가 90%%를 넘었지만 조금씩 다르다는 것을 알 수 있었다. 5가지 모델에 대한 정확도를 코드 작성해서 돌려봤더니 Random Forest 모델과 SVM 모델의 정확도가 가장 높았던 것을 확인할 수 있었다. Decision Tree 모델이 93.9%로 이 5가지 학습 모델 중에서는 가장 정확도가 떨어지는 것 또한 확인이 가능했다.\n",
        "\n",
        "모델을 구동시킨 후 표로 나오는 precision, recall, f1-score, support의 의미를 아직 완전히 이해하지 못하였지만 정확도를 구함으로써 어느 모델이 좀 더 높은 정확도를 끌어올릴 수 있는지를 알 수 있었던 소중한 시간이었다."
      ],
      "metadata": {
        "id": "bbTrgZpfUT7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load_wine : 와인분류"
      ],
      "metadata": {
        "id": "s5ORj3UhluF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. 필요한 모듈 import하기"
      ],
      "metadata": {
        "id": "7G2eRffGlzUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                              # 정확도를 구하고자 할 때 들여와야 하는 구문이다. accuracy_score로 import한다는 뜻이다.\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "tN6IfdJtl4yp"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. 데이터 준비"
      ],
      "metadata": {
        "id": "XvVf1hwLl94H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine = load_wine()\n",
        "\n",
        "print(dir(wine))\n",
        "wine.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LRffp7qmAkD",
        "outputId": "e04e8ac8-8a99-4ea3-95e6-3c1fe2d55028"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine_data = wine.data\n",
        "\n",
        "print(wine_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj7llqWemDOn",
        "outputId": "6f2ba013-12cb-466c-973a-c01a8fb794a3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.3. 데이터 이해하기"
      ],
      "metadata": {
        "id": "sn_KyUJymGEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine_label = wine.target              # 와인 데이터를 타겟 변수에 저장하는 과정\n",
        "print(wine_label.shape)               # label의 데이터 형태 출력. 1차원 178개 데이터 존재 확인\n",
        "wine_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__znxEpvmIm_",
        "outputId": "52fe5f93-134c-4a83-8e08-16cd3f785434"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.target_names         # 와인 데이터의 타겟명을 불러보니 class 0,1,2가 나오는 것을 확인할 수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT4eR3JDmLJ5",
        "outputId": "a46bbcd1-a950-4e76-b60d-db3eb65a59c0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.feature_names    # 와인 데이터의 특성명을 불러보니 알코올이나 말릭산 등등 다양한 특성들이 나온다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF2ZmNOZmPaJ",
        "outputId": "890cee7a-6872-49d6-e42c-f4b71df8c107"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alcohol',\n",
              " 'malic_acid',\n",
              " 'ash',\n",
              " 'alcalinity_of_ash',\n",
              " 'magnesium',\n",
              " 'total_phenols',\n",
              " 'flavanoids',\n",
              " 'nonflavanoid_phenols',\n",
              " 'proanthocyanins',\n",
              " 'color_intensity',\n",
              " 'hue',\n",
              " 'od280/od315_of_diluted_wines',\n",
              " 'proline']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "wine_df = pd.DataFrame(data=wine_data, columns=wine.feature_names)\n",
        "wine_df\n",
        "# 와인 데이터셋을 pandas가 제공하는 DataFrame이라는 자료형으로 변환한 후 보여주는 구문이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "AUTB3rKpmTF1",
        "outputId": "bb6c4e3c-589d-4f28-a589-cf919fe02a12"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
              "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
              "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
              "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
              "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  \n",
              "0                            3.92   1065.0  \n",
              "1                            3.40   1050.0  \n",
              "2                            3.17   1185.0  \n",
              "3                            3.45   1480.0  \n",
              "4                            2.93    735.0  \n",
              "..                            ...      ...  \n",
              "173                          1.74    740.0  \n",
              "174                          1.56    750.0  \n",
              "175                          1.56    835.0  \n",
              "176                          1.62    840.0  \n",
              "177                          1.60    560.0  \n",
              "\n",
              "[178 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0dca6555-f501-4578-b3e4-878c031efe26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0dca6555-f501-4578-b3e4-878c031efe26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0dca6555-f501-4578-b3e4-878c031efe26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0dca6555-f501-4578-b3e4-878c031efe26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df['label'] = wine.target               \n",
        "wine_df\n",
        "# label이라는 코드로 0~2까지의 숫자 데이터들로 구성된 라벨을 추가하여 데이터프레임을 다시 보여줬다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "UQgWnWOumXRg",
        "outputId": "79426d17-f118-4fa5-b365-c76b0995d261"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
              "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
              "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
              "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
              "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  label  \n",
              "0                            3.92   1065.0      0  \n",
              "1                            3.40   1050.0      0  \n",
              "2                            3.17   1185.0      0  \n",
              "3                            3.45   1480.0      0  \n",
              "4                            2.93    735.0      0  \n",
              "..                            ...      ...    ...  \n",
              "173                          1.74    740.0      2  \n",
              "174                          1.56    750.0      2  \n",
              "175                          1.56    835.0      2  \n",
              "176                          1.62    840.0      2  \n",
              "177                          1.60    560.0      2  \n",
              "\n",
              "[178 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd16756e-ae98-4aa1-9712-6bcbdb94cfd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd16756e-ae98-4aa1-9712-6bcbdb94cfd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd16756e-ae98-4aa1-9712-6bcbdb94cfd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd16756e-ae98-4aa1-9712-6bcbdb94cfd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. Train, Test 데이터 분리"
      ],
      "metadata": {
        "id": "4g2Ae0wEmZgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size=0.2, random_state=7)\n",
        "\n",
        "print('X_train 개수: ', len(X_train),'X_test 개수: ', len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEjlfujymmgC",
        "outputId": "0c1f3bbc-54f8-4b7e-856a-605da033199e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train 개수:  142 X_test 개수:  36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5. 다양한 모델로 학습시켜보기"
      ],
      "metadata": {
        "id": "RcaVJG22mp_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.5.1 Decision Tree 모델\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(random_state = 15)\n",
        "\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ehwTrgxmpNZ",
        "outputId": "dfff0b15-b4dc-441e-bb45-b27093ae2dc0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93         7\n",
            "           1       0.89      0.94      0.91        17\n",
            "           2       1.00      0.83      0.91        12\n",
            "\n",
            "    accuracy                           0.92        36\n",
            "   macro avg       0.92      0.92      0.92        36\n",
            "weighted avg       0.92      0.92      0.92        36\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9166666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.5.2 Random Forest 모델\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(random_state=32)\n",
        "\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNPOHRWemvO3",
        "outputId": "c5e59705-e486-4bfb-c072-ec562c3b2af5"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       1.00      1.00      1.00        17\n",
            "           2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.5.3 SVM 사용해보기\n",
        "\n",
        "from sklearn import svm\n",
        "svm_model = svm.SVC()\n",
        "\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "kogMJ6g5myWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.5.4 SGD 사용해보기\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier()\n",
        "\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "lrmOA-7Nm0b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.5.5 Logistic Regression 사용해보기\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c10h51fDm3E4",
        "outputId": "d1a84878-9a6b-4ab2-fd2d-142e5dcadab8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92         7\n",
            "           1       0.94      1.00      0.97        17\n",
            "           2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.95      0.96        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9722222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.6. 결론\n",
        "와인 데이터셋에서도 역시 Random Forest 모델이 가장 학습 효율이 높은 것으로 드러났다. 학습 효율의 가장 중요한 척도가 되는 정확도(accuracy)를 비교하여 내린 결론이다. 정확도 비교 내역은 다음과 같다.\n",
        "\n",
        "SVM < SGD < Decision Tree < Logistic Regression < Random Forest"
      ],
      "metadata": {
        "id": "jYBdAma3m5gL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load_breast_cancer : 유방암 여부 진단\n"
      ],
      "metadata": {
        "id": "kdSmWN2WnDYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "유방암 여부를 판별하는 이번 데이터셋에서는 필요한 모듈 import부터 모델 학습 및 예측(decision tree)을 한번에 노트로 정리해 보았다."
      ],
      "metadata": {
        "id": "l2xr-87pnP_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) 필요한 모듈 import\n",
        "import sklearn\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# (2) 데이터 준비\n",
        "breast_cancer = load_breast_cancer()\n",
        "breast_cancer_data = breast_cancer.data\n",
        "breast_cancer_label = breast_cancer.target"
      ],
      "metadata": {
        "id": "B99hbh8TnCqi"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) 데이터 이해하기\n",
        "breast_cancer_label = breast_cancer.target     # 유방암 데이터를 타겟 변수에 저장하는 과정\n",
        "print(breast_cancer_label.shape)               # label의 데이터 형태 출력. 1차원 569개 데이터 존재 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKo-EoUnnpjD",
        "outputId": "43839a18-4aa8-4337-bc1c-75d37a085445"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer.target_names      # 유방암의 타겟명은 악성(malignant), 양성(benign) 2가지가 존재함을 알 수 있다.\n",
        "breast_cancer.feature_names          # 유방암의 특성명이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWt1YsdFnpvh",
        "outputId": "9713e388-62dc-4a6b-8cc9-b383d14f8929"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "breast_cancer_df = pd.DataFrame(data=breast_cancer_data, columns=breast_cancer.feature_names)\n",
        "breast_cancer_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "rQfdPPT5np3X",
        "outputId": "64b0f55f-fd1c-459a-d0e0-3443fa7a557e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a39cd21e-58c3-4ede-978f-84edc33ef785\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a39cd21e-58c3-4ede-978f-84edc33ef785')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a39cd21e-58c3-4ede-978f-84edc33ef785 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a39cd21e-58c3-4ede-978f-84edc33ef785');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_df['label'] = breast_cancer.target               \n",
        "breast_cancer_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "2Fo47Umgnp7z",
        "outputId": "50d867c1-bc23-4086-f180-c662eb834271"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                   0.07871  ...          17.33           184.60      2019.0   \n",
              "1                   0.05667  ...          23.41           158.80      1956.0   \n",
              "2                   0.05999  ...          25.53           152.50      1709.0   \n",
              "3                   0.09744  ...          26.50            98.87       567.7   \n",
              "4                   0.05883  ...          16.67           152.20      1575.0   \n",
              "..                      ...  ...            ...              ...         ...   \n",
              "564                 0.05623  ...          26.40           166.10      2027.0   \n",
              "565                 0.05533  ...          38.25           155.00      1731.0   \n",
              "566                 0.05648  ...          34.12           126.70      1124.0   \n",
              "567                 0.07016  ...          39.42           184.60      1821.0   \n",
              "568                 0.05884  ...          30.37            59.16       268.6   \n",
              "\n",
              "     worst smoothness  worst compactness  worst concavity  \\\n",
              "0             0.16220            0.66560           0.7119   \n",
              "1             0.12380            0.18660           0.2416   \n",
              "2             0.14440            0.42450           0.4504   \n",
              "3             0.20980            0.86630           0.6869   \n",
              "4             0.13740            0.20500           0.4000   \n",
              "..                ...                ...              ...   \n",
              "564           0.14100            0.21130           0.4107   \n",
              "565           0.11660            0.19220           0.3215   \n",
              "566           0.11390            0.30940           0.3403   \n",
              "567           0.16500            0.86810           0.9387   \n",
              "568           0.08996            0.06444           0.0000   \n",
              "\n",
              "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
              "0                  0.2654          0.4601                  0.11890      0  \n",
              "1                  0.1860          0.2750                  0.08902      0  \n",
              "2                  0.2430          0.3613                  0.08758      0  \n",
              "3                  0.2575          0.6638                  0.17300      0  \n",
              "4                  0.1625          0.2364                  0.07678      0  \n",
              "..                    ...             ...                      ...    ...  \n",
              "564                0.2216          0.2060                  0.07115      0  \n",
              "565                0.1628          0.2572                  0.06637      0  \n",
              "566                0.1418          0.2218                  0.07820      0  \n",
              "567                0.2650          0.4087                  0.12400      0  \n",
              "568                0.0000          0.2871                  0.07039      1  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-621fc395-7fa1-4f62-a6c5-5381d1df0c30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-621fc395-7fa1-4f62-a6c5-5381d1df0c30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-621fc395-7fa1-4f62-a6c5-5381d1df0c30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-621fc395-7fa1-4f62-a6c5-5381d1df0c30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) Train, Test 데이터 분리\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data, breast_cancer_label, test_size=0.2, random_state=7)\n",
        "print('X_train 개수: ', len(X_train),'X_test 개수: ', len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejG4kaNLnp_c",
        "outputId": "cb2f4bb7-95f0-4ae3-c502-a47f300064c4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train 개수:  455 X_test 개수:  114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.1) Decision Tree 모델\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(random_state = 15)\n",
        "\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FJHw3iCnqCi",
        "outputId": "62301fa0-70b9-4644-d097-2c5109856a06"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        40\n",
            "           1       0.96      0.96      0.96        74\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.94      0.94      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9473684210526315"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.2) Random Forest 모델\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(random_state=32)\n",
        "\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrYOKJYbn6qc",
        "outputId": "a84617fb-98fc-4300-b878-3b5f74a03db2"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        40\n",
            "           1       1.00      1.00      1.00        74\n",
            "\n",
            "    accuracy                           1.00       114\n",
            "   macro avg       1.00      1.00      1.00       114\n",
            "weighted avg       1.00      1.00      1.00       114\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (5.3) SVM 사용해보기\n",
        "\n",
        "from sklearn import svm\n",
        "svm_model = svm.SVC()\n",
        "\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6m2irIun6uc",
        "outputId": "0f44ea25-5d8e-454c-c74b-0047c84e1767"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.72      0.84        40\n",
            "           1       0.87      1.00      0.93        74\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.94      0.86      0.89       114\n",
            "weighted avg       0.92      0.90      0.90       114\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9035087719298246"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.4 SGD 사용해보기\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier()\n",
        "\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifD9t5MBn6y7",
        "outputId": "b86aee6f-8385-4f9f-e13e-2187295463cf"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.93      0.84        40\n",
            "           1       0.95      0.85      0.90        74\n",
            "\n",
            "    accuracy                           0.88       114\n",
            "   macro avg       0.86      0.89      0.87       114\n",
            "weighted avg       0.89      0.88      0.88       114\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8771929824561403"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.5 Logistic Regression 사용해보기\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXCf5qPln633",
        "outputId": "42b1550e-9d62-4c32-a402-93fbf9f59fcf"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90        40\n",
            "           1       0.91      1.00      0.95        74\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.96      0.91      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9385964912280702"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 총론\n",
        "지금까지 손글씨, 와인, 유방암 3가지 데이터셋을 가져와서 사이킷런에서 제공하는 5가지 학습모델을 통해 학습을 시켜 보는 실습을 해 보았다. accuracy, 즉 정확도가 학습 효율에 큰 영향이 미치는 것을 알게 되었으며 3가지 데이터셋 모두 공통적으로 5가지 학습모델 중 정확도가 가장 높은 Random Forest의 학습 효율이 가장 높음을 알 수 있었다. 하지만 precision, recall, f1-score, support에 관한 개념은 아직 이해가 되지 않아 머신 러닝에 대해 더 많이 공부해야겠다는 생각이 들었다."
      ],
      "metadata": {
        "id": "RO5yFM3JoAmw"
      }
    }
  ]
}